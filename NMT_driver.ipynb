{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT_driver.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMnSpNVfH+Lf07WSnhGbq+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markaaronslater/NMT/blob/master/NMT_driver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qngiJLEPEzWv"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZXApLY8E9xw"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGiBT-uxXleg"
      },
      "source": [
        "!pip install subword-nmt # for segmenting words into subwords\n",
        "!pip install stanza # for tokenizing corpus and tagging with morphological data\n",
        "!pip install sacremoses # for detokenizing model predictions\n",
        "!pip install sacrebleu # for evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVINnIj9E_N0"
      },
      "source": [
        "# make sure using GPU\n",
        "# (Runtime -> Change runtime type -> Hardware accelerator = GPU).\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w_rcYx8JVY5"
      },
      "source": [
        "# recommended: place cloned NMT folder in Google drive folder 'My Drive':\n",
        "path = '/content/gdrive/My Drive/NMT/'\n",
        "corpus_path = path + 'corpuses/iwslt16_en_de/'\n",
        "config_path = path + 'configs/'\n",
        "# give model a name representing, e.g., major hyperparameter setting differences from other models, etc.\n",
        "model_name = 'my_model/' # name of model tensor batches, hyperparameters, etc., saved as pickle file inside data_path\n",
        "checkpoint_path = path + 'checkpoints/' + model_name\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgAPTgJxhNGz"
      },
      "source": [
        "%cd /content/gdrive/My Drive/NMT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgyoFSHKJ5Z-"
      },
      "source": [
        "from src.preprocessing.apply_stanza_processors import apply_stanza_processors\n",
        "from src.preprocessing.truecase import truecase_corpuses\n",
        "from src.import_configs import import_configs\n",
        "from src.preprocessing.preprocess import construct_model_data, retrieve_model_data\n",
        "from src.train import train, load_checkpoint\n",
        "from src.predict import predict\n",
        "from src.evaluate import evaluate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW65cehmKRh2"
      },
      "source": [
        "# only meaningful for unit tests on subsets of corpus data, where _start is starting line number,\n",
        "# (using 1-based indexing) and num is how many lines to extract. if num is None, then extract all lines from _start till end of corpus.\n",
        "# _start = 1\n",
        "# num = None\n",
        "# num = 10 # uncomment this line if unit testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJNv2c22F3U-"
      },
      "source": [
        "# step 1 - tokenize corpuses, and tag with morphological data.\n",
        "apply_stanza_processors(\"train.de\", \"train.en\", \"dev.de\", \"test.de\", path=corpus_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFNueYblGugP"
      },
      "source": [
        "# step 2 - true-case corpuses using linguistic heuristics that leverage morphological\n",
        "# data produced by morphological data tagger.\n",
        "truecase_corpuses(\"train.de\", \"train.en\", \"dev.de\", \"test.de\", corpus_path=corpus_path):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPdPJEq1dVkg"
      },
      "source": [
        "# import vocab, training, and model hyperparameter settings from configuration files.\n",
        "hyperparams = import_configs(config_path=config_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZH_5k34It3l"
      },
      "source": [
        "# step 3 - segment words of corpuses into subwords (skip this cell if using a word-level vocabulary).\n",
        "num_merge_ops = hyperparams[\"num_merge_ops\"]\n",
        "vocab_threshold = hyperparams[\"vocab_threshold\"]\n",
        "truecased_path = corpus_path + 'truecased/'\n",
        "segmented_path = corpus_path + 'subword_segmented/'\n",
        "\n",
        "!bash ./src/preprocessing/subword_joint.sh $num_merge_ops $vocab_threshold \"$truecased_path\" \"$segmented_path\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44V9gcJFIxIo"
      },
      "source": [
        "p = corpus_path + 'subword_segmented/' # point p to the preprocessed corpuses to be directly used by model \n",
        "\n",
        "# step 4 - build intelligently batched sets of tensors that can be directly passed to model.\n",
        "train_batches, dev_batches, vocabs, hyperparams = construct_model_data(\"train.de\", \"train.en\", \"dev.de\", \"test.de\",\n",
        "                                          hyperparams=hyperparams, corpus_path=p, checkpoint_path=checkpoint_path\n",
        "                                                                                                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJy_MNEYI8rA"
      },
      "source": [
        "# step 5 - instantiate and train model.\n",
        "\n",
        "model, loss = train(hyperparams, train_batches, dev_batches, dev_references, idx_to_trg_word, checkpoint_path, save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VugDFUDn4NKn"
      },
      "source": [
        "model = model[0]\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEGpCZHaSp9g"
      },
      "source": [
        "# step 5 - evaluate test set predictions.\n",
        "\n",
        "# # can load a checkpoint rather than using prev cell's model:\n",
        "# if hyperparams[\"early_stopping\"]:\n",
        "#     model = load_checkpoint(hyperparams, checkpoint_path, \"best_model\")\n",
        "# else:\n",
        "#     model, _ = load_checkpoint(hyperparams, checkpoint_path, \"most_recent_model\")\n",
        "\n",
        "# use beam search instead of greedy search.\n",
        "model.decoder.set_inference_alg(\"beam_search\")\n",
        "\n",
        "# change to test_batches\n",
        "# get test batches\n",
        "\n",
        "\n",
        "# (can read predictions inside checkpoints/beam_preds.txt)\n",
        "dev_translations, preds_time, post_time = predict(model, dev_batches, idx_to_trg_word, checkpoint_path)\n",
        "bleu = evaluate(dev_translations, dev_references)\n",
        "print(round(bleu, 2))\n",
        "print(preds_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjjOnoLqdqW_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEAsgWD9drH5"
      },
      "source": [
        "# b) run unit tests to show correctness of model implementations\n",
        "# can run each separately, or discover and run all at once (see below)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuHPjynIdsRy"
      },
      "source": [
        "# allow ~5 min to run all model variant tests, each of which trains for 100 epochs.\n",
        "!python -m pytest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyxUz19gdwnk"
      },
      "source": [
        "!python -m pytest unittests/test_batches.py # ensure intelligent batching procedure is correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYlVCoG8d2QB"
      },
      "source": [
        "!python -m pytest -s -v unittests/test_model.py::test_default_word_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I5U-E2Pd3w5"
      },
      "source": [
        "!python -m pytest -s -v unittests/test_model.py::test_default_subword_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMfDOm5cd4NA"
      },
      "source": [
        "# before running this cell, ensure using cpu\n",
        "# (Runtime -> Change runtime type -> Hardware accelerator = None).\n",
        "# allow several minutes for this test to run.\n",
        "!python -m pytest -s -v unittests/test_model.py::test_default_word_model_cpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yswqiBh-d4Rv"
      },
      "source": [
        "!python -m pytest -s -v unittests/test_model.py::test_uni_no_attn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fff63SwWd4QQ"
      },
      "source": [
        "!python -m pytest -s -v unittests/test_model.py::test_layer_to_layer_uni_no_attn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w96UHQY7d_7b"
      },
      "source": [
        "!python -m pytest -s -v unittests/test_model.py::test_final_to_first_uni_no_attn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT_hHRukeCyg"
      },
      "source": [
        "!python -m pytest -s -v unittests/test_model.py::test_dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw0FFyyUO2OO"
      },
      "source": [
        "!python -m pytest -s -v unittests/test_model.py::test_no_tying"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zsp9-LcMCsJ"
      },
      "source": [
        "!python -m pytest -s -v unittests/test_model.py::test_no_attn_no_tying"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zH30UpheC3a"
      },
      "source": [
        "# c) load a pre-trained model checkpoint to determine BLEU score on test set.\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}