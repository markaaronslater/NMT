{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "playground.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPzhbZMXWLMfIMYQj56I6rJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markaaronslater/NMT/blob/master/playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjKS-XepHBMy"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkGwarO9-62Z",
        "outputId": "0cd96d1b-0b27-439e-e68b-5f3b16ef927d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjK38odg-8jA",
        "outputId": "5038c65b-21ff-465e-945d-68b4e781259a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "!pip install subword-nmt # for segmenting words into subwords\n",
        "!pip install stanza # for tokenizing corpus and tagging with morphological data\n",
        "!pip install sacremoses # for detokenizing model predictions\n",
        "!pip install sacrebleu # for evaluation\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting subword-nmt\n",
            "  Downloading https://files.pythonhosted.org/packages/74/60/6600a7bc09e7ab38bc53a48a20d8cae49b837f93f5842a41fe513a694912/subword_nmt-0.3.7-py2.py3-none-any.whl\n",
            "Installing collected packages: subword-nmt\n",
            "Successfully installed subword-nmt-0.3.7\n",
            "Collecting stanza\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/8b/3a9e7a8d8cb14ad6afffc3983b7a7322a3a24d94ebc978a70746fcffc085/stanza-1.1.1-py3-none-any.whl (227kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.18.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.12.4)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.7.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (50.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.1.1\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.41.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=2f58048ff5504186a58dab46eb8e7e78a60168b59fdd2e777f403dbbb75e0204\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.43\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.7MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Installing collected packages: portalocker, sacrebleu\n",
            "Successfully installed portalocker-2.0.0 sacrebleu-1.4.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzAGPwIj--Jp",
        "outputId": "a1ad27ed-4b37-429f-ccfb-4ce58e4b68af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# make sure using GPU\n",
        "# (Runtime -> Change runtime type -> Hardware accelerator = GPU).\n",
        "!nvidia-smi\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Nov  7 01:26:37 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5h17Mnv-_pm",
        "outputId": "16fa2009-e3f5-4c02-91bf-70db6b17d4ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "%cd /content/gdrive/My Drive/NMT\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/NMT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRs8rx7V_Blx"
      },
      "source": [
        "\n",
        "from src.model_utils import load_pretrained\n",
        "from src.translate import translate\n",
        "from src.predict import predict\n",
        "from src.evaluate import evaluate\n",
        "from src.preprocessing.corpus_utils import read_corpus, get_references\n",
        "\n",
        "import stanza\n",
        "from subword_nmt.apply_bpe import BPE\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKY4XS-W_Dfh"
      },
      "source": [
        "# recommended path to project root directory: place cloned NMT folder in 'My Drive' folder of Google Drive account:\n",
        "path = '/content/gdrive/My Drive/NMT/'\n",
        "model_name = 'modified_replica/' # name of pre-trained model to load\n",
        "checkpoint_path = path + 'checkpoints/' + model_name\n",
        "#corpus_path = path + 'corpuses/iwslt16_en_de/subword_segmented/'\n",
        "corpus_path = path + 'data/iwslt/en-de/subword_segmented/'\n",
        "### ??how to give them access to my pre-trained model?? too large to commit to github??\n",
        "\n",
        "translator, model_data = load_pretrained(checkpoint_path=checkpoint_path)\n",
        "#test_batches = model_data[\"test_batches\"]\n",
        "src_word_to_idx = model_data[\"src_word_to_idx\"]\n",
        "idx_to_trg_word = model_data[\"idx_to_trg_word\"]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqdhNJwk_GG4",
        "outputId": "2220d1bf-e2fc-4ee6-f911-0e3d457dff12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "stanza.download(lang='de', processors='tokenize,mwt,pos')\n",
        "stanza_de_processor = stanza.Pipeline(lang='de', processors='tokenize,mwt,pos', tokenize_no_ssplit=True, tokenize_batch_size=64, mwt_batch_size=200, pos_batch_size=10000)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 17.0MB/s]                    \n",
            "2020-11-07 01:28:58 INFO: Downloading these customized packages for language: de (German)...\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | gsd     |\n",
            "| mwt       | gsd     |\n",
            "| pos       | gsd     |\n",
            "| pretrain  | gsd     |\n",
            "=======================\n",
            "\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.1.0/de/tokenize/gsd.pt: 100%|██████████| 651k/651k [00:00<00:00, 2.18MB/s]\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.1.0/de/mwt/gsd.pt: 100%|██████████| 546k/546k [00:00<00:00, 2.49MB/s]\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.1.0/de/pos/gsd.pt: 100%|██████████| 22.4M/22.4M [00:06<00:00, 3.56MB/s]\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.1.0/de/pretrain/gsd.pt: 100%|██████████| 157M/157M [00:12<00:00, 12.7MB/s]\n",
            "2020-11-07 01:29:19 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2020-11-07 01:29:19 INFO: Loading these models for language: de (German):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | gsd     |\n",
            "| mwt       | gsd     |\n",
            "| pos       | gsd     |\n",
            "=======================\n",
            "\n",
            "2020-11-07 01:29:19 INFO: Use device: gpu\n",
            "2020-11-07 01:29:19 INFO: Loading: tokenize\n",
            "2020-11-07 01:29:19 INFO: Loading: mwt\n",
            "2020-11-07 01:29:19 INFO: Loading: pos\n",
            "2020-11-07 01:29:20 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7YvL_WR_HQd"
      },
      "source": [
        "bpe = BPE(open(corpus_path + 'bpe_codes', 'r'), vocab=set(src_word_to_idx))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zN2qtlOIljr",
        "outputId": "a2200bfc-a7e2-45c2-bf2c-bd3cd3d49ede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# a) translation playground:\n",
        "# place any number of whatever German sentences you want as strings inside following list:\n",
        "input = [\"Dies ist ein deutscher Testsatz. Wird das Modell es erfolgreich übersetzen können?\", \n",
        "         \"Wenn nicht, wird diese Demo nicht sehr beeindruckend sein ...\",\n",
        "         \"Ich empfehle, dass Sie zuerst einen englischen Satz erstellen und ihn dann mit Google Translate in Deutsch konvertieren.\"]\n",
        "\n",
        "# determined via Google Translate:\n",
        "sample_targets = [\"This is a German test sentence. Will the model be able to translate it successfully?\",\n",
        "                  \"If it doesn't, then this demo will not be very impressive...\",\n",
        "                  \"I recommend that you first come up with an English sentence, and then use Google Translate to convert it to German.\"]\n",
        "\n",
        "translations = translate(input, stanza_de_processor, translator, src_word_to_idx, idx_to_trg_word, bpe, device='cuda:0', bsz=8)\n",
        "for translation in translations:\n",
        "    print(translation)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenizing, multiword-token-expanding, pos-tagging...\n",
            "truecasing...\n",
            "subword segmenting...\n",
            "converting to batches of indices...\n",
            "making predictions...\n",
            "This is a German test. Will it be able to translate it?\n",
            "If not, this Demo won't be very impressive...\n",
            "I suggest that you're going to create a English sentence, and then you put it with Google transcendent in German.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUC6xNIBz0q5",
        "outputId": "25cd3238-2c75-4bcf-f5b1-3ff680def94d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# optional - if targets are available, evaluate via BLEU metric:\n",
        "print(evaluate(translations, [sample_targets]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33.748833981791414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZBxjIipKifR"
      },
      "source": [
        "!sacrebleu --list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXuSow61U69I",
        "outputId": "7ceeb99d-4711-414a-b0b3-fdb59af7c2b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# b) replicate BLEU score on test set\n",
        "test_path = path + 'data/iwslt/en-de/'\n",
        "test_set = read_corpus('test.de', path=test_path)\n",
        "test_references = get_references(path=test_path, dev=False)\n",
        "translations = translate(test_set, stanza_de_processor, translator, src_word_to_idx, idx_to_trg_word, bpe)\n",
        "print(evaluate(translations, test_references))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenizing, multiword-token-expanding, pos-tagging...\n",
            "truecasing...\n",
            "subword segmenting...\n",
            "converting to batches of indices...\n",
            "making predictions...\n",
            "25.08855376005401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMwQTFJuHCwa",
        "outputId": "52312cac-302d-41f8-a71a-914714306103",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# b) replicate BLEU score on test set\n",
        "\n",
        "\n",
        "\n",
        "# download iwslt17 test set\n",
        "!sacrebleu -t iwslt17 -l de-en --echo src > iwslt17-de-en.src"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/en/fr/en-fr.tgz to /root/.sacrebleu/iwslt17/en-fr.tgz\n",
            "sacreBLEU: Checksum passed: 1849bcc3b006dc0642a8843b11aa7192\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/en-fr.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/fr/en/fr-en.tgz to /root/.sacrebleu/iwslt17/fr-en.tgz\n",
            "sacreBLEU: Checksum passed: 79bf7a2ef02d226875f55fb076e7e473\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/fr-en.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/en/de/en-de.tgz to /root/.sacrebleu/iwslt17/en-de.tgz\n",
            "sacreBLEU: Checksum passed: b68e7097b179491f6c466ef41ad72b9b\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/en-de.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/de/en/de-en.tgz to /root/.sacrebleu/iwslt17/de-en.tgz\n",
            "sacreBLEU: Checksum passed: e3f5b2a075a2da1a395c8b60bf1e9be1\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/de-en.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/en/ar/en-ar.tgz to /root/.sacrebleu/iwslt17/en-ar.tgz\n",
            "sacreBLEU: Checksum passed: ecdc6bc4ab4c8984e919444f3c05183a\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/en-ar.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/ar/en/ar-en.tgz to /root/.sacrebleu/iwslt17/ar-en.tgz\n",
            "sacreBLEU: Checksum passed: 4b5141d14b98706c081371e2f8afe0ca\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/ar-en.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/en/ja/en-ja.tgz to /root/.sacrebleu/iwslt17/en-ja.tgz\n",
            "sacreBLEU: Checksum passed: d957ee79de1f33c89077d37c5a2c5b06\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/en-ja.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/ja/en/ja-en.tgz to /root/.sacrebleu/iwslt17/ja-en.tgz\n",
            "sacreBLEU: Checksum passed: c213e8bb918ebf843543fe9fd2e33db2\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/ja-en.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/en/ko/en-ko.tgz to /root/.sacrebleu/iwslt17/en-ko.tgz\n",
            "sacreBLEU: Checksum passed: 59f6a81c707378176e9ad8bb8d811f5f\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/en-ko.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/ko/en/ko-en.tgz to /root/.sacrebleu/iwslt17/ko-en.tgz\n",
            "sacreBLEU: Checksum passed: 7e580af973bb389ec1d1378a1850742f\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/ko-en.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/en/zh/en-zh.tgz to /root/.sacrebleu/iwslt17/en-zh.tgz\n",
            "sacreBLEU: Checksum passed: 975a858783a0ebec8c57d83ddd5bd381\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/en-zh.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/zh/en/zh-en.tgz to /root/.sacrebleu/iwslt17/zh-en.tgz\n",
            "sacreBLEU: Checksum passed: cc51d9b7fe1ff2af858c6a0dd80b8815\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/zh-en.tgz\n",
            "sacreBLEU: Processing /root/.sacrebleu/iwslt17/raw/de-en/IWSLT17.TED.tst2017.de-en.de.xml to /root/.sacrebleu/iwslt17/de-en.de\n",
            "sacreBLEU: Processing /root/.sacrebleu/iwslt17/raw/en-de/IWSLT17.TED.tst2017.en-de.en.xml to /root/.sacrebleu/iwslt17/de-en.en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p0QWFZjHh0P",
        "outputId": "d164ab4e-39e2-4fd3-d880-baf17c1666fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_set = read_corpus('iwslt17-de-en.src', path='/content/gdrive/My Drive/NMT/')\n",
        "translations = translate(test_set, stanza_de_processor, translator, src_word_to_idx, idx_to_trg_word, bpe)\n",
        "!cat beam_preds.txt | sacrebleu -t iwslt17 -l de-en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenizing, multiword-token-expanding, pos-tagging...\n",
            "truecasing...\n",
            "subword segmenting...\n",
            "converting to batches of indices...\n",
            "making predictions...\n",
            "BLEU+case.mixed+lang.de-en+numrefs.1+smooth.exp+test.iwslt17+tok.13a+version.1.4.14 = 21.6 58.4/30.8/17.8/10.5 (BP = 0.899 ratio = 0.904 hyp_len = 18958 ref_len = 20972)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvOZEephcwOn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9zY2Rswcwww"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZlO2LCncwzL",
        "outputId": "23f67047-5f02-41eb-8f6a-b03ce13b83d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!sacrebleu -t iwslt17/tst2016 -l de-en --echo src > isthisthetestset.src"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/en/fr/en-fr.tgz to /root/.sacrebleu/iwslt17/tst2016/en-fr.tgz\n",
            "sacreBLEU: Checksum passed: 1849bcc3b006dc0642a8843b11aa7192\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/tst2016/en-fr.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/fr/en/fr-en.tgz to /root/.sacrebleu/iwslt17/tst2016/fr-en.tgz\n",
            "sacreBLEU: Checksum passed: 79bf7a2ef02d226875f55fb076e7e473\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/tst2016/fr-en.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/en/de/en-de.tgz to /root/.sacrebleu/iwslt17/tst2016/en-de.tgz\n",
            "sacreBLEU: Checksum passed: b68e7097b179491f6c466ef41ad72b9b\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/tst2016/en-de.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/de/en/de-en.tgz to /root/.sacrebleu/iwslt17/tst2016/de-en.tgz\n",
            "sacreBLEU: Checksum passed: e3f5b2a075a2da1a395c8b60bf1e9be1\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/tst2016/de-en.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/en/zh/en-zh.tgz to /root/.sacrebleu/iwslt17/tst2016/en-zh.tgz\n",
            "sacreBLEU: Checksum passed: 975a858783a0ebec8c57d83ddd5bd381\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/tst2016/en-zh.tgz\n",
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/zh/en/zh-en.tgz to /root/.sacrebleu/iwslt17/tst2016/zh-en.tgz\n",
            "sacreBLEU: Checksum passed: cc51d9b7fe1ff2af858c6a0dd80b8815\n",
            "sacreBLEU: Extracting /root/.sacrebleu/iwslt17/tst2016/zh-en.tgz\n",
            "sacreBLEU: Processing /root/.sacrebleu/iwslt17/tst2016/raw/de-en/IWSLT17.TED.tst2016.de-en.de.xml to /root/.sacrebleu/iwslt17/tst2016/de-en.de\n",
            "sacreBLEU: Processing /root/.sacrebleu/iwslt17/tst2016/raw/en-de/IWSLT17.TED.tst2016.en-de.en.xml to /root/.sacrebleu/iwslt17/tst2016/de-en.en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LF4iQrEcw2Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CipgjGIdcw5R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}