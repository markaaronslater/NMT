{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "playground.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNYCudzp0pfPFxMwY/Fg+GS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markaaronslater/NMT/blob/master/playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjKS-XepHBMy"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkGwarO9-62Z",
        "outputId": "a8f7daec-54f9-4db0-d4e1-01804fe0e819",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjK38odg-8jA",
        "outputId": "f6cd3ab9-5ae3-4273-b809-bc7ecc9ff1cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "!pip install subword-nmt # for segmenting words into subwords\n",
        "!pip install stanza # for tokenizing corpus and tagging with morphological data\n",
        "!pip install sacremoses # for detokenizing model predictions\n",
        "!pip install sacrebleu # for evaluation\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting subword-nmt\n",
            "  Downloading https://files.pythonhosted.org/packages/74/60/6600a7bc09e7ab38bc53a48a20d8cae49b837f93f5842a41fe513a694912/subword_nmt-0.3.7-py2.py3-none-any.whl\n",
            "Installing collected packages: subword-nmt\n",
            "Successfully installed subword-nmt-0.3.7\n",
            "Collecting stanza\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/8b/3a9e7a8d8cb14ad6afffc3983b7a7322a3a24d94ebc978a70746fcffc085/stanza-1.1.1-py3-none-any.whl (227kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (50.3.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.1.1\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.41.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=20eff72477284e0d88f65b0463ad0bb4a3276c78fd7e3864f1649bde3d84a74b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.43\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.3MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Installing collected packages: portalocker, sacrebleu\n",
            "Successfully installed portalocker-2.0.0 sacrebleu-1.4.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzAGPwIj--Jp",
        "outputId": "5639a641-dc38-4c91-d705-7ecdd9bbc0c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# make sure using GPU\n",
        "# (Runtime -> Change runtime type -> Hardware accelerator = GPU).\n",
        "!nvidia-smi\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Nov  6 00:38:25 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5h17Mnv-_pm",
        "outputId": "2e8ae8dc-8414-49fd-d7a6-29c9de989c56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "%cd /content/gdrive/My Drive/NMT\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/NMT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRs8rx7V_Blx"
      },
      "source": [
        "\n",
        "from src.model_utils import load_pretrained\n",
        "from src.translate import translate\n",
        "from src.predict import predict\n",
        "from src.evaluate import evaluate\n",
        "\n",
        "import stanza\n",
        "from subword_nmt.apply_bpe import BPE\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKY4XS-W_Dfh"
      },
      "source": [
        "# recommended path to project root directory: place cloned NMT folder in 'My Drive' folder of Google Drive account:\n",
        "path = '/content/gdrive/My Drive/NMT/'\n",
        "model_name = 'old_replica/' # name of pre-trained model to load\n",
        "checkpoint_path = path + 'checkpoints/' + model_name\n",
        "corpus_path = path + 'corpuses/iwslt16_en_de/subword_segmented/'\n",
        "### ??how to give them access to my pre-trained model?? too large to commit to github??\n",
        "\n",
        "translator, model_data = load_pretrained(checkpoint_path=checkpoint_path)\n",
        "#test_batches = model_data[\"test_batches\"]\n",
        "src_word_to_idx = model_data[\"src_word_to_idx\"]\n",
        "idx_to_trg_word = model_data[\"idx_to_trg_word\"]\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqdhNJwk_GG4",
        "outputId": "74f89068-d97b-432c-b191-887c4301c96a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "stanza.download(lang='de', processors='tokenize,mwt,pos')\n",
        "stanza_de_processor = stanza.Pipeline(lang='de', processors='tokenize,mwt,pos', tokenize_no_ssplit=True, tokenize_batch_size=64, mwt_batch_size=200, pos_batch_size=10000)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 30.4MB/s]                    \n",
            "2020-11-06 00:54:31 INFO: Downloading these customized packages for language: de (German)...\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | gsd     |\n",
            "| mwt       | gsd     |\n",
            "| pos       | gsd     |\n",
            "| pretrain  | gsd     |\n",
            "=======================\n",
            "\n",
            "2020-11-06 00:54:31 INFO: File exists: /root/stanza_resources/de/tokenize/gsd.pt.\n",
            "2020-11-06 00:54:31 INFO: File exists: /root/stanza_resources/de/mwt/gsd.pt.\n",
            "2020-11-06 00:54:31 INFO: File exists: /root/stanza_resources/de/pos/gsd.pt.\n",
            "2020-11-06 00:54:31 INFO: File exists: /root/stanza_resources/de/pretrain/gsd.pt.\n",
            "2020-11-06 00:54:31 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2020-11-06 00:54:31 INFO: Loading these models for language: de (German):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | gsd     |\n",
            "| mwt       | gsd     |\n",
            "| pos       | gsd     |\n",
            "=======================\n",
            "\n",
            "2020-11-06 00:54:31 INFO: Use device: gpu\n",
            "2020-11-06 00:54:31 INFO: Loading: tokenize\n",
            "2020-11-06 00:54:32 INFO: Loading: mwt\n",
            "2020-11-06 00:54:32 INFO: Loading: pos\n",
            "2020-11-06 00:54:33 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7YvL_WR_HQd"
      },
      "source": [
        "bpe = BPE(open(corpus_path + 'bpe_codes', 'r'), vocab=set(src_word_to_idx))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zN2qtlOIljr",
        "outputId": "52c79544-f964-42ee-aa58-549458913944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# a) translation playground:\n",
        "# place any number of whatever German sentences you want as strings inside following list:\n",
        "input = [\"Dies ist ein deutscher Testsatz. Wird das Modell es erfolgreich übersetzen können?\", \n",
        "         \"Wenn nicht, wird diese Demo nicht sehr beeindruckend sein ...\",\n",
        "         \"Ich empfehle, dass Sie zuerst einen englischen Satz erstellen und ihn dann mit Google Translate in Deutsch konvertieren.\"]\n",
        "\n",
        "# determined via Google Translate:\n",
        "sample_targets = [\"This is a German test sentence. Will the model be able to translate it successfully?\",\n",
        "                  \"If it doesn't, then this demo will not be very impressive...\",\n",
        "                  \"I recommend that you first come up with an English sentence, and then use Google Translate to convert it to German.\"]\n",
        "\n",
        "translations = translate(input, stanza_de_processor, translator, src_word_to_idx, idx_to_trg_word, bpe, device='cuda:0', bsz=8)\n",
        "for translation in translations:\n",
        "    print(translation)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenizing, multiword-token-expanding, pos-tagging...\n",
            "truecasing...\n",
            "subword segmenting...\n",
            "converting to batches of indices...\n",
            "making predictions...\n",
            "This is a German test. Will the model be able to translate it?\n",
            "If not, this demo is not very impressive...\n",
            "I suggest that you're going to make a English sentence, and then you put it with Google Translate in German.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUC6xNIBz0q5"
      },
      "source": [
        "# optional - if targets are available, evaluate via BLEU metric:\n",
        "print(evaluate(translations, [sample_targets])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMwQTFJuHCwa"
      },
      "source": [
        "# b) replicate BLEU score on test set\n",
        "\n",
        "\n",
        "\n",
        "# download iwslt17 test set\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}